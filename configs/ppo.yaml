experiment_name: ppo_HC
algo: ppo
env: HalfCheetahCustom-v0

train:
  total_env_steps: 500_000
  seed: 42
  learning_rate: 0.001     
  n_steps: 4096             
  batch_size: 256           
  n_epochs: 20              
  gamma: 0.99
  clip_range: 0.2

eval:
  episodes: 1
  seeds: [0,1,2,3,4,5,6,7,8,9]
