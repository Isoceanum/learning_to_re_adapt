experiment_name: ppo_hopper_sanity
algo: ppo
env: HopperCustom-v0

train:
  total_env_steps: 200_000
  seed: 42
  learning_rate: 0.001     # slightly lower for stability
  n_steps: 4096             # longer rollouts per env
  batch_size: 256           # larger batch for stability
  n_epochs: 20              # more optimization passes per batch
  gamma: 0.99
  clip_range: 0.2

eval:
  episodes: 1
  seeds: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
