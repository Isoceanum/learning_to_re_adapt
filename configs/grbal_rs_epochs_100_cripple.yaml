experiment_name: grbal_rs_epochs_100_cripple
algo: grbal
env: HalfCheetahCustom-v0 #HopperCustom-v0 HalfCheetahCustom-v0 AntCustom-v0
device: auto # cpu or cuda
# total real env steps are given as num_rollouts * max_path_length * train_iterations
train:
  seed: 42
  max_path_length: 1000 #FAITHFUL
  num_rollouts: 64          # rollouts per iteration; steps_per_iter = num_rollouts * max_path_length
  train_iterations: 16     # total GrBAL iterations (iteration 0 is the random warmup)
  eval_interval_steps: 50_000

  meta_batch_size: 10        #FAITHFUL meta-tasks per outer update in dynamics model.fit
  adapt_batch_size: 32       #FAITHFUL length of support/query window and online adaptation sliding window
  inner_lr: 0.01              #FAITHFUL  GrBAL inner-loop learning rate for compute_adapted_params
  inner_steps: 1             #FAITHFUL  number of inner gradient steps in compute_adapted_params
  rolling_average_persitency: 0.99  # EMA factor for validation loss during dynamics fit

  perturbation:
    type: action_scaling
    probability: 1
    candidate_action_indices: [0,1,2,3,4,5]
    range: [0.0, 0.0]

  # Dynamics model
  hidden_sizes: [512, 512, 512]    #FAITHFUL
  learning_rate: 0.001             #FAITHFUL
  train_epochs: 100                 #FAITHFUL
  valid_split_ratio: 0.2     # hold out 10% of the batch for validation # GOOD

  # MPC planner
  planner:
    type: "rs" # rs cem mppi
    horizon: 10
    n_candidates: 1000
    discount: 0.99

eval:
  # evaluation phase
  episodes: 10
  seeds: [0,1,2,3,4,5,6,7,8,9]

  # MPC planner
  planner:
    type: "rs" # rs cem mppi
    horizon: 15
    n_candidates: 2500
    discount: 0.99

  perturbation:
    type: action_scaling
    probability: 1
    candidate_action_indices: [0,1,2,3,4,5]
    range: [0.0, 0.0]
