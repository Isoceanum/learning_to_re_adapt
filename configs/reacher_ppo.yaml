experiment_name: reacher_ppo_baseline
algo: ppo
env: ReacherCustom-v0

train:
  n_envs: 16
  total_timesteps: 1_000_000
  learning_rate: 0.0003
  n_steps: 256                  
  batch_size: 256
  n_epochs: 5
  gamma: 0.99
  clip_range: 0.2

eval:
  episodes: 50
  seeds: [0, 1, 2, 3, 4]
  deterministic: true
  save_csv: true
