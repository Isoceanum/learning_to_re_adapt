experiment_name: grbal_HC_disabled_metaep100
algo: grbal_fidelity
env: HalfCheetahCustom-v0 #HopperCustom-v0 HalfCheetahCustom-v0 AntCustom-v0
device: auto # cpu or cuda 

train:
  seed: 42
  max_path_length: 1000
  total_env_steps: 1_000_000
  steps_per_iter: 10_000
  eval_interval_steps: 50_000

  perturbation:
    type: action_scaling
    probability: 1
    candidate_action_indices: [0,1,2,3,4]
    range: [0.0, 0.0]

  # Dynamics model
  pretrain_epochs: 10
  hidden_sizes: [256, 256, 256] # GOOD 
  learning_rate: 0.001       # GOOD but call it dynamkc model 
  train_epochs: 100          # max epochs per iteration (same as Nagabandi’s dynamic_model_epochs) # GOOD 
  valid_split_ratio: 0.1     # hold out 10% of the batch for validation # GOOD 
  patience: 5                # stop if validation loss hasn’t improved for 5 consecutive epochs # GOOD 

  # mpc planner
  planner: "rs" # rs cem
  horizon: 20
  n_candidates: 2_000
  discount: 0.99

  # meta data windowing
  past_window_size: 32  # segment_sampler slices this many steps per episode for the support window.
  future_window_size: 32  # segment_sampler slices this many subsequent steps per episode for the query window.
  meta_batch_size: 32  # meta_trainer pulls this many (support, query) windows per outer iteration.

  # inner / outer adaptation
  inner_lr: 0.01  # inner_update applies this step size when adapting the cloned dynamics parameters.
  inner_steps: 1  # number of gradient steps InnerUpdater performs on the support loss before evaluating the query loss.
  meta_outer_lr: 0.001  # MetaTrainer’s Adam optimizer uses this learning rate for the outer meta-gradient update.
  meta_epochs_per_iteration: 100 # aggressive outer updates per 10k env steps

eval:
  # evaluation phase
  episodes: 10
  seeds: [0,1,2,3,4,5,6,7,8,9]

  perturbation:
    type: action_scaling
    probability: 1
    candidate_action_indices: [0,1,2,3,4]
    range: [0.0, 0.0]
