experiment_name: reacher_mbmpc__baseline
algo: mb_mpc
env: ReacherCustom-v0


train:
  # MB-MPC training loop settings
  total_iterations: 10        # number of dataset aggregation iterations
  init_random_steps: 500     # steps with random actions (iteration 1)
  rollout_steps: 1000         # steps using planner in subsequent iterations
  epochs: 20                  # dynamics model epochs per iteration

  # Dynamics + planner hyperparameters
  hidden_sizes: [128, 128]
  lr: 0.001
  batch_size: 256
  val_ratio: 0.1
  horizon: 10
  num_candidates: 500
  device: cuda                 # or "cuda" if available
  ensemble_size: 3            # set to 1 for baseline, 5 for uncertainty
  # ctrl_cost_weight: 0.001   # optional; env default is used if present

  # Planner knobs
  num_elites: 50             # elites per CEM iteration
  max_iters: 5                # CEM iterations
  alpha: 0.2                  # smoothing for mean/std updates
  particles: 1                # TSâˆž particles per candidate
  aggregate: mean             # mean | risk_averse
  risk_coef: 0.0              # only used if aggregate=risk_averse

eval:
  episodes: 4
  seeds: [0,1,2,3]
  deterministic: true
  save_csv: true
