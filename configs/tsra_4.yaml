experiment_name: tsra_4
algo: tsra
env: GymAnt-v0
device: auto # cpu or cuda
exclude_current_positions_from_observation: true

train:
  seed: 42 # Global RNG seed for reproducibility
  max_episode_length: 1000 # Max steps per episode rollout during data collection
  data_collection_policy: planner # random | base | planner
  eval_interval_steps: 1000
  iterations: 5
  steps_per_iteration: 2000
  train_epochs: 30
  batch_size: 256
  valid_split_ratio: 0.1

  pretrained_dynamics_model:
    model_path:  "/global/D1/homes/ismailou/l2ra/learning_to_re_adapt/outputs/2026-02-09/ant_base_dynamics_epoch_30/model.pt"
    config_path: "/global/D1/homes/ismailou/l2ra/learning_to_re_adapt/outputs/2026-02-09/ant_base_dynamics_epoch_30/config.yaml"

    #model_path:  "outputs/2026-01-09-ex3/ant_base_dynamics_steps_10k/model.pt"
    #config_path: "outputs/2026-01-09-ex3/ant_base_dynamics_steps_10k/config.yaml"

  residual_adapter:
     hidden_sizes: [64, 64]
     learning_rate: 5e-5
     enabled: true

  planner:
    type: "cem"
    horizon: 15
    n_candidates: 250
    discount: 0.99
    num_cem_iters: 4
    percent_elites: 0.15
    alpha: 0.20


  perturbation:
    type: action_inversion
    probability: 1
    candidate_action_indices: [4]

eval:
  episodes: 1 # Number of episodes to run per seed
  seeds: [0,1,2,3,4] # Evaluation seeds
  k_list: [1, 2, 5, 10, 15]

  perturbation:
    type: action_inversion
    probability: 1
    candidate_action_indices: [4]